{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook: Práctica iterativa (simple y didáctica)\n",
        "\n",
        "Esta notebook te guía paso a paso. Cambia **solo** las variables `catalog` y `schema` para decidir dónde se crean las tablas.\n",
        "\n",
        "**Tablas que se crearán**:\n",
        "- Entrada: `iris_input`\n",
        "- Intermedia: `iris_intermediate`\n",
        "- Final: `iris_predictions`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1) Preparar el entorno: instala dependencias mínimas\n",
        "%pip install pandas scikit-learn mlflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 2) Configura tu espacio (cámbialo por el tuyo)\n",
        "catalog = \"demo_uc\"   # p. ej., \"main\" o tu catálogo\n",
        "schema  = \"validacion\" # p. ej., \"sandbox\" o tu esquema\n",
        "\n",
        "table_input       = f\"{catalog}.{schema}.iris_input\"\n",
        "table_intermediate= f\"{catalog}.{schema}.iris_intermediate\"\n",
        "table_predictions = f\"{catalog}.{schema}.iris_predictions\"\n",
        "\n",
        "print(\"Usando:\")\n",
        "print(\"  Entrada     :\", table_input)\n",
        "print(\"  Intermedia  :\", table_intermediate)\n",
        "print(\"  Predicciones:\", table_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Cargar dataset público y crear tabla de **entrada**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "spark_df = spark.createDataFrame(df)\n",
        "spark_df.write.mode(\"overwrite\").saveAsTable(table_input)\n",
        "display(spark.table(table_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Crear tabla **intermedia** (transformación simple)\n",
        "En un caso real harías varias transformaciones; aquí solo añadimos una columna sencilla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df_intermediate = df.copy()\n",
        "df_intermediate[\"petal_area\"] = df_intermediate[\"petal_length\"] * df_intermediate[\"petal_width\"]\n",
        "spark.createDataFrame(df_intermediate).write.mode(\"overwrite\").saveAsTable(table_intermediate)\n",
        "display(spark.table(table_intermediate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Entrenar un modelo muy sencillo (clasificación)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import mlflow.sklearn\n",
        "\n",
        "X = df_intermediate.drop(columns=[\"species\"])  # features\n",
        "y = df_intermediate[\"species\"]                 # etiqueta\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "acc = accuracy_score(y_test, model.predict(X_test))\n",
        "print(f\"Exactitud del modelo: {acc:.2f}\")\n",
        "\n",
        "# Registro de ejemplo en MLflow\n",
        "mlflow.sklearn.log_model(model, \"modelo_logistico_demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Guardar tabla **final** con predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "preds = model.predict(X_test)\n",
        "df_preds = pd.DataFrame({\n",
        "    \"real\": y_test.values,\n",
        "    \"prediccion\": preds\n",
        "})\n",
        "spark.createDataFrame(df_preds).write.mode(\"overwrite\").saveAsTable(table_predictions)\n",
        "display(spark.table(table_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Opcional) Comparar con otras tablas de otros equipos\n",
        "Si cuentas con acceso de solo lectura a otros catálogos/esquemas, puedes comparar resultados con un `JOIN`.\n",
        "Ejemplo SQL (ajusta nombres reales):\n",
        "```sql\n",
        "SELECT a.*, b.prediccion AS pred_otro\n",
        "FROM demo_uc.validacion.iris_predictions a\n",
        "LEFT JOIN prod_uc.linea1.iris_predictions b\n",
        "  ON a.real = b.real\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}